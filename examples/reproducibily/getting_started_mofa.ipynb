{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOFA+: training a model in Python\n",
    "Author: Ricard Argelaguet.    \n",
    "Affiliation: European Bioinformatics Institute, Cambridge, UK.  \n",
    "Date: 13/11/2019  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a detailed tutorial on how to train MOFA using Python.\n",
    "A template script to run the code below can be found [here](https://github.com/bioFAM/MOFA2/tree/master/inst/scripts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T20:25:16.898360Z",
     "start_time": "2020-02-06T20:25:16.836870Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        #########################################################\n",
      "        ###           __  __  ____  ______                    ### \n",
      "        ###          |  \\/  |/ __ \\|  ____/\\    _             ### \n",
      "        ###          | \\  / | |  | | |__ /  \\ _| |_           ### \n",
      "        ###          | |\\/| | |  | |  __/ /\\ \\_   _|          ###\n",
      "        ###          | |  | | |__| | | / ____ \\|_|            ###\n",
      "        ###          |_|  |_|\\____/|_|/_/    \\_\\              ###\n",
      "        ###                                                   ### \n",
      "        ######################################################### \n",
      "       \n",
      " \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from mofapy2.run.entry_point import entry_point\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# initialise the entry point\n",
    "ent = entry_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load data\n",
    "\n",
    "To create a MOFA+ object you need to specify four dimensions: samples (cells), features, view(s) and group(s). MOFA objects can be created from a wide range of input formats:\n",
    "\n",
    "### 2.1) pandas data.frame format\n",
    "A pandas data.frame with columns `sample`, `group`, `feature`, `view`, `value`.  This is the most intuitive format, as it summarises all omics/groups in a single data structure. Also, there is no need to add rows that correspond to missing data.\n",
    "\n",
    "For example:\n",
    "```\n",
    "sample   group   feature    value   view\n",
    "sample1  groupA  gene1      2.8044  RNA\n",
    "sample1  groupA  gene3      2.2069  RNA\n",
    "sample2  groupB  gene2      0.1454  RNA\n",
    "sample2  groupB  gene1      2.7021  RNA\n",
    "sample2  groupB  promoter1  3.8618  Methylation\n",
    "sample3  groupB  promoter2  3.2545  Methylation\n",
    "sample3  groupB  promoter3  1.5014  Methylation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load a simulated data set with the following dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T20:25:20.952029Z",
     "start_time": "2020-02-06T20:25:18.586476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>group</th>\n",
       "      <th>feature</th>\n",
       "      <th>view</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_0_group_0</td>\n",
       "      <td>group_0</td>\n",
       "      <td>feature_0_view_0</td>\n",
       "      <td>view_0</td>\n",
       "      <td>-2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1_group_0</td>\n",
       "      <td>group_0</td>\n",
       "      <td>feature_0_view_0</td>\n",
       "      <td>view_0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_2_group_0</td>\n",
       "      <td>group_0</td>\n",
       "      <td>feature_0_view_0</td>\n",
       "      <td>view_0</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_3_group_0</td>\n",
       "      <td>group_0</td>\n",
       "      <td>feature_0_view_0</td>\n",
       "      <td>view_0</td>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_4_group_0</td>\n",
       "      <td>group_0</td>\n",
       "      <td>feature_0_view_0</td>\n",
       "      <td>view_0</td>\n",
       "      <td>-0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sample    group           feature    view  value\n",
       "0  sample_0_group_0  group_0  feature_0_view_0  view_0  -2.05\n",
       "1  sample_1_group_0  group_0  feature_0_view_0  view_0   0.10\n",
       "2  sample_2_group_0  group_0  feature_0_view_0  view_0   1.44\n",
       "3  sample_3_group_0  group_0  feature_0_view_0  view_0  -0.28\n",
       "4  sample_4_group_0  group_0  feature_0_view_0  view_0  -0.88"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = [1000,1000] # Number of features per view\n",
    "M = len(D)      # Number of views\n",
    "K = 5           # Number of factors\n",
    "N = [100,100]   # Number of samples per group\n",
    "G = len(N)      # Number of groups\n",
    "\n",
    "data_dt = pd.read_csv(\"http://ftp.ebi.ac.uk/pub/databases/mofa/getting_started/data.txt.gz\", sep=\"\\t\")\n",
    "data_dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) List of matrices\n",
    "A nested list of numpy arrays, where the first index refers to the view and the second index refers to the group. Samples are stored in the rows and features are stored in the columns. All views for a given group G must have the same samples in the rows. If there is any sample that is missing a particular view, the column needs to be filled with NAs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the same data above in matrix format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T20:25:21.324421Z",
     "start_time": "2020-02-06T20:25:21.058184Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_prefix = \"http://ftp.ebi.ac.uk/pub/databases/mofa/getting_started\"\n",
    "data_mat = [[None for g in range(G)] for m in range(M)]\n",
    "for m in range(M):\n",
    "    for g in range(G):\n",
    "        data_mat[m][g] = np.loadtxt(\"%s/%d_%d.txt.gz\" % (data_prefix,m,g), delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### 2.3 Define data options\n",
    "- **scale_views**: if views have different ranges/variances, it is good practice to scale each view to unit variance. Default is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T20:25:21.371541Z",
     "start_time": "2020-02-06T20:25:21.359823Z"
    }
   },
   "outputs": [],
   "source": [
    "ent.set_data_options(\n",
    "    scale_views = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4) Add the data to the model\n",
    "\n",
    "This has to be run after defining the data options\n",
    "- **likelihoods**: a list of strings, either \"gaussian\" (default), \"poisson\" or \"bernoulli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T20:25:21.862319Z",
     "start_time": "2020-02-06T20:25:21.805782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View names not provided, using default naming convention:\n",
      "- view1, view2, ..., viewM\n",
      "\n",
      "Features names not provided, using default naming convention:\n",
      "- feature1_view1, featureD_viewM\n",
      "\n",
      "Groups names not provided, using default naming convention:\n",
      "- group1, group2, ..., groupG\n",
      "\n",
      "Samples names not provided, using default naming convention:\n",
      "- sample1_group1, sample2_group1, sample1_group2, ..., sampleN_groupG\n",
      "\n",
      "Successfully loaded view='view0' group='group0' with N=100 samples and D=1000 features...\n",
      "Successfully loaded view='view0' group='group1' with N=100 samples and D=1000 features...\n",
      "Successfully loaded view='view1' group='group0' with N=100 samples and D=1000 features...\n",
      "Successfully loaded view='view1' group='group1' with N=100 samples and D=1000 features...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# option 1: data.frame format\n",
    "ent.set_data_df(data_dt, likelihoods = [\"gaussian\",\"gaussian\"])\n",
    "\n",
    "# option 2: nested matrix format\n",
    "ent.set_data_matrix(data_mat, likelihoods = [\"gaussian\",\"gaussian\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Set model options\n",
    "\n",
    "- **factors**: number of factors\n",
    "- **spikeslab_weights**: use spike-slab sparsity prior in the weights? default is TRUE\n",
    "- **ard_weights**: use ARD prior in the weights? Default is TRUE if using multiple views.\n",
    "\n",
    "Only change the default model options if you are familiar with the underlying mathematical model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T20:25:26.955109Z",
     "start_time": "2020-02-06T20:25:26.914220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model options:\n",
      "- Automatic Relevance Determination prior on the factors: True\n",
      "- Automatic Relevance Determination prior on the weights: True\n",
      "- Spike-and-slab prior on the factors: False\n",
      "- Spike-and-slab prior on the weights: True \n",
      "\n",
      "Likelihoods:\n",
      "- View 0 (view0): gaussian\n",
      "- View 1 (view1): gaussian\n"
     ]
    }
   ],
   "source": [
    "ent.set_model_options(\n",
    "    factors = 10, \n",
    "    spikeslab_weights = True, \n",
    "    ard_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Set training options\n",
    "\n",
    "- **convergence_mode**: \"fast\" (default), \"medium\", \"slow\".\n",
    "- **dropR2**: minimum variance explained criteria to drop factors while training\n",
    "- **gpu_mode**: use GPU? (needs cupy installed and a functional GPU, see https://biofam.github.io/MOFA2/gpu_training.html)\n",
    "- **seed**: random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T20:25:29.519460Z",
     "start_time": "2020-02-06T20:25:29.509712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU mode is activated, but GPU not found... switching to CPU mode\n",
      "For GPU mode, you need:\n",
      "1 - Make sure that you are running MOFA+ on a machine with an NVIDIA GPU\n",
      "2 - Install CUPY following instructions on https://docs-cupy.chainer.org/en/stable/install.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ent.set_train_options(\n",
    "    convergence_mode = \"fast\", \n",
    "    dropR2 = 0.001, \n",
    "    gpu_mode = True, \n",
    "    seed = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Build and train the MOFA object \n",
    "\n",
    "After training, the model will be saved as an hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T20:27:21.866240Z",
     "start_time": "2020-02-06T20:27:18.843347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "######################################\n",
      "## Training the model with seed 1 ##\n",
      "######################################\n",
      "\n",
      "\n",
      "ELBO before training: -5381458.89 \n",
      "\n",
      "Iteration 1: time=0.06, ELBO=-575232.56, deltaELBO=4806226.336 (89.31084362%), Factors=9\n",
      "Iteration 2: time=0.07, ELBO=-475536.26, deltaELBO=99696.298 (1.85258867%), Factors=8\n",
      "Iteration 3: time=0.06, ELBO=-467044.81, deltaELBO=8491.451 (0.15779088%), Factors=7\n",
      "Iteration 4: time=0.05, ELBO=-462583.09, deltaELBO=4461.713 (0.08290899%), Factors=6\n",
      "Iteration 5: time=0.06, ELBO=-459116.18, deltaELBO=3466.915 (0.06442334%), Factors=5\n",
      "Iteration 6: time=0.04, ELBO=-458285.22, deltaELBO=830.956 (0.01544108%), Factors=5\n",
      "Iteration 7: time=0.04, ELBO=-457814.07, deltaELBO=471.158 (0.00875520%), Factors=5\n",
      "Iteration 8: time=0.04, ELBO=-457487.58, deltaELBO=326.485 (0.00606685%), Factors=5\n",
      "Iteration 9: time=0.06, ELBO=-457202.99, deltaELBO=284.587 (0.00528829%), Factors=5\n",
      "Iteration 10: time=0.04, ELBO=-456926.93, deltaELBO=276.062 (0.00512988%), Factors=5\n",
      "Iteration 11: time=0.05, ELBO=-456666.10, deltaELBO=260.835 (0.00484693%), Factors=5\n",
      "Iteration 12: time=0.11, ELBO=-456437.43, deltaELBO=228.665 (0.00424912%), Factors=5\n",
      "Iteration 13: time=0.08, ELBO=-456246.66, deltaELBO=190.774 (0.00354502%), Factors=5\n",
      "Iteration 14: time=0.04, ELBO=-456087.59, deltaELBO=159.067 (0.00295584%), Factors=5\n",
      "Iteration 15: time=0.05, ELBO=-455950.33, deltaELBO=137.263 (0.00255067%), Factors=5\n",
      "Iteration 16: time=0.06, ELBO=-455826.84, deltaELBO=123.490 (0.00229474%), Factors=5\n",
      "Iteration 17: time=0.04, ELBO=-455710.86, deltaELBO=115.979 (0.00215515%), Factors=5\n",
      "Iteration 18: time=0.05, ELBO=-455597.76, deltaELBO=113.095 (0.00210156%), Factors=5\n",
      "Iteration 19: time=0.05, ELBO=-455485.19, deltaELBO=112.574 (0.00209190%), Factors=5\n",
      "Iteration 20: time=0.05, ELBO=-455372.67, deltaELBO=112.518 (0.00209085%), Factors=5\n",
      "Iteration 21: time=0.06, ELBO=-455259.13, deltaELBO=113.542 (0.00210987%), Factors=5\n",
      "Iteration 22: time=0.05, ELBO=-455141.61, deltaELBO=117.515 (0.00218370%), Factors=5\n",
      "Iteration 23: time=0.05, ELBO=-455017.31, deltaELBO=124.306 (0.00230989%), Factors=5\n",
      "Iteration 24: time=0.05, ELBO=-454890.60, deltaELBO=126.711 (0.00235458%), Factors=5\n",
      "Iteration 25: time=0.06, ELBO=-454777.30, deltaELBO=113.294 (0.00210527%), Factors=5\n",
      "Iteration 26: time=0.07, ELBO=-454687.38, deltaELBO=89.924 (0.00167099%), Factors=5\n",
      "Iteration 27: time=0.08, ELBO=-454621.75, deltaELBO=65.626 (0.00121948%), Factors=5\n",
      "Iteration 28: time=0.06, ELBO=-454575.85, deltaELBO=45.908 (0.00085308%), Factors=5\n",
      "Iteration 29: time=0.24, ELBO=-454540.91, deltaELBO=34.939 (0.00064925%), Factors=5\n",
      "Iteration 30: time=0.06, ELBO=-454510.81, deltaELBO=30.094 (0.00055922%), Factors=5\n",
      "Iteration 31: time=0.06, ELBO=-454483.09, deltaELBO=27.720 (0.00051509%), Factors=5\n",
      "Iteration 32: time=0.07, ELBO=-454457.65, deltaELBO=25.444 (0.00047280%), Factors=5\n",
      "Iteration 33: time=0.09, ELBO=-454435.35, deltaELBO=22.304 (0.00041445%), Factors=5\n",
      "Iteration 34: time=0.04, ELBO=-454416.89, deltaELBO=18.454 (0.00034292%), Factors=5\n",
      "Iteration 35: time=0.06, ELBO=-454402.44, deltaELBO=14.450 (0.00026852%), Factors=5\n",
      "Iteration 36: time=0.06, ELBO=-454391.52, deltaELBO=10.926 (0.00020303%), Factors=5\n",
      "Iteration 37: time=0.04, ELBO=-454383.33, deltaELBO=8.189 (0.00015217%), Factors=5\n",
      "Iteration 38: time=0.05, ELBO=-454377.13, deltaELBO=6.200 (0.00011521%), Factors=5\n",
      "Iteration 39: time=0.06, ELBO=-454372.32, deltaELBO=4.807 (0.00008932%), Factors=5\n",
      "Iteration 40: time=0.06, ELBO=-454368.46, deltaELBO=3.858 (0.00007169%), Factors=5\n",
      "Iteration 41: time=0.04, ELBO=-454365.23, deltaELBO=3.230 (0.00006002%), Factors=5\n",
      "Iteration 42: time=0.05, ELBO=-454362.40, deltaELBO=2.828 (0.00005256%), Factors=5\n",
      "Iteration 43: time=0.05, ELBO=-454359.82, deltaELBO=2.585 (0.00004804%), Factors=5\n",
      "Iteration 44: time=0.05, ELBO=-454357.37, deltaELBO=2.452 (0.00004556%), Factors=5\n",
      "\n",
      "Converged!\n",
      "\n",
      "\n",
      "\n",
      "#######################\n",
      "## Training finished ##\n",
      "#######################\n",
      "\n",
      "\n",
      "No output file name provided as a training options or to the save method. Saving to /tmp/mofa_20210223-153612.hdf5 .\n",
      "Saving model in /tmp/mofa_20210223-153612.hdf5...\n"
     ]
    }
   ],
   "source": [
    "ent.build()\n",
    "\n",
    "ent.run()\n",
    "\n",
    "# Save the output\n",
    "ent.save(outfile=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Downstream analysis\n",
    "\n",
    "This finishes the tutorial on how to train a MOFA model from python. To continue with the downstream analysis you can either use the [mofax](https://github.com/gtca/mofax) python package or the [MOFA2](https://www.bioconductor.org/packages/release/bioc/html/MOFA2.html) R package. Please, visit our [tutorials](https://biofam.github.io/MOFA2/tutorials.html) webpage for more information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "latex_metadata": {
   "affiliation": "European Bioinformatics Institute, Cambridge, UK",
   "author": "Ricard Argelaguet",
   "title": "MOFA+: training a model with Python"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
